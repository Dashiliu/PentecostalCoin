# client包和yarn包的任务提交流程分析

**首先确认2个问题:**

**1.Flink是什么,或者说mr/spark这些是什么**

计算引擎啥的说的比较形象,我觉得换个易懂的是分布式调度框架,就是

把你原来自己写的任务,通过他提供的API,算子对job进行拆分成更细的task,

再由他提供的分布式节点计算逻辑发送到对应节点上运行,每个节点一般只有1到几个算子的task,

并在执行过程中保证你能看见你的任务是一个整体的在运行,并能在出错时进行恢复,

在这个基础上,再提供一些task级,调度级,资源管理级,数据传输级,任务编写API级等的优化.

的这种框架,目的就是帮你开箱即用分布式,性能还更好,资源还能更可控.

*由此可见Flink2020年的发展已经可以确认主功能已经可提供生产,即用原语言开发流/批任务已经没有问题,但是编写任务的API还不够完善,比如sql/python等,其他一些比较火的业务场景没有相应插件,比如算法,图计算等*

**2.任务提交是什么**

任务提交就是

通过命令行或者rest api或者webui等的各种渠道,把你自己编写的job传给Flink,

由Flink进行拆分成task,优化,计算部署节点,并申请资源,提交到各个节点,确认提交成功并通知提交程序ok的过程.

*在Flink中主要由Flink-client负责提交通过 Java SPI 确定要提交到哪种资源管理框架上(可以是Flink 自己的single,cluster集群,可以是yarn,k8s...),flink-yarn是在工作中最常用的一种资源管理框架.*